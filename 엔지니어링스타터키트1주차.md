# 실리콘벨리에서 날아온 데이터 엔지니어링 스타터 키트

##  1주차 

### 1. 데이터 팀의 역할 소개

* 요즘 세상에서 커리어란?
	* 뭘 모르는지 물어봐야함 ? 물어보는 것을 두려워하지 말아야 한다. 자문자답 혹은 다른 사람에게 물어봄.. 내가 뭘 모르는지도 모르는 상태 .. 
	* 나보다 잘하는 사람들보고 기죽지 말자. 이 분야를 공부했던 사람이겠지 .. 하고 무던하게 생각하자.
	* 요즘 인생은 워터폴이 아니고 애자일한 인생
* 데이터 팀의 구조 (데이터 조직의 목표)
	* 파이썬, SQL, 오케스트레이션 도구, DATABASE를 알아야 함. 
	* 엔지니어가 DW를 만들고 ETL로 데이터를 적재함
	* DW에서 데이터 분석가가 데이터를 분석함
	* 데이터 과학자가 머신러닝 등을 활용하여 서비스를 개선
* 데이터 조직의 비전
	* 데이터 팀은 서포트 조직
	* 데이터의 품질이 굉장히 중요
	* 데이터팀이 구체적으로 어떤 관점에서 도움이 되는가?
		* 지표를 만듦으로써 회사 결정/발전에 도움이 됨
		* 목표는 어디인데 확인할 수 있게 해줌
		* data driven decisions - 나는 별 생각이 없고 데이터가 하는데로 갈래 (항상 좋은 것은 아님)
		* data informed decisions - 나는 어떤 생각을 가지고 있고 데이터를 가지고 참고할래 (방향이 있고 방향이 맞는지 아닌지 참고)
		* 데이터는 과거의 사실을 가지고 현재를 최적화 함, 안해봤던 일은 경험이 없으니 결정할 수 없음 
		* 결론은 혁신보다는 했던 일을 최적화 하는 방향으로 가는 것. data informed decisions가 더 좋다. 
	* 데이터 사언티스트 
		* 회사 운영을 최적화
	* 개인 정보를 어떻게 관리할 것인지가 중요한 요소임
* 데이터 조직에 어떤 사람들이 있는가
	* 데이터 엔지니어
	* 데이터 분석가
	* 데이터 과학자
	* 분석 엔지니어, ML 엔지니어, MLOps, 개인정보 엔지니어(Privacy Engineer), ... (파생직군들)
* 데이터 과학자 
	* 알고리즘으로 서비스 개선 (시간이 오래 걸림, 끈기가 있어야 하고, 너무 이론적이지 않고 practical .. , 박사학위가 유리 - 토픽을 연구해서 결과를 냄, 쉽게 포기하지 않음)
	* 머신러닝 알고리즘으로 패턴을 찾아 결과를 냄
	* 스킬셋 
		* 머신러닝 
		* 파이썬 / 스파크
		* SQL / hive(?)
		* R / SAS / Matlab
	* ML Model Development Cycle
		* 애자일하게 따름
		* 데이터 수집 -> 분석 -> 모델  -> 알고리즘 배포 -> A/B 테스트(성능 검증) -> 데이터 수집 
		* 10 번정도 애자일하게 반복한 경험이 있으심 
	* 누가 좋은 데이터 과학자를 만드는가?
		* 열정 (문제 해결에 대한)
		* 데이터
		* 잘하는 데이터 사이언티스트는 
			* 풀고싶은 욕망이 커서 붙들고 늘어지면 모델 하나 만들고 경험으로 쩜프할 수 있다.
		* 코딩, 현실적 문제 해결 방법, 이런 것은 부차적이다.
	* 요즘은 어떻게 데이터 과학자가 되는가 
		* 내가 직접 문제를 풀어보는 것. 강의 참고해서 끈기있게. 확실하게 배우는 방법
* 데이터 분석가
	* BI를 책임지는 사람
		* 지표 정의, 시각화, 현업부서의 궁금증에 답해주는 것
		* 회사 문화가 중요해짐 - 빨리 대답해주기를 원함
		* SQL, 통계, 도메인 지식이 중요
	* 딜레마 (회사 문화에 따라 다름)
		* 매일 다양한 문제에 대한 답을 하는 것
			* 내가 성장하고 있나?
			* 잘한다는 기준은 뭐지? 내 고과는 어떻게 매겨지지?
		* 데이터 팀이 아니라 현업 부서에 포함된 경우도 많음
			* 중앙 데이터 팀이 없으면 아무리 잘해도 2등.. 잘하는 사람부터 나간다.
		* 잘하는데 그만둘 것 같은 친구들은 내부에서 전직을 시켜줌
			* internal transfer 한 직군에 1년 이상 있고 퍼포먼스가 좋다면 다른 일을 할 수 있게 해줌(매니저 권한)
* 데이터 엔지니어
	* DW 만드는 사람 (vs 데이터 레이크)
		* Redshift, BigQuery, Snowflake .. 
		* ETL 
	* A/B Test
		* 데이터 엔지니어들이 A/B 테스트 구축을 많이 한다.(백엔드 엔지니어와 함께)
	* Data Tools
		* 데이터 분석가, 사이언티스트가 사용할 툴 개발 .. (회바회)
* 조직구조 
	* 중앙집중화 (centralized) - 가장 일반적, 현업 부서에서는 답답..
	* 분산형태 (Distributed or Decentralized) - 각 팀에서 비슷한 프로젝트를 진행, 너무 많은 사람들이 
	* **하이브리드 형태 (Hybrid) - 중앙 형태에서 6개월 1년씩 순환 구조를 채택**
* Case study
	* Tulip - 화장터에서 화장해주는 마켓
		* 영국 장의사로 일하던 2명이 미국으로 와서 만든 스타트업
			* 바가지 안쓰고, 언제 찾아갈지 트래킹해준다.
		* 이런 서비스는 마케팅이 가장 중요
			* 실험 기반의 마케팅 (인스타, 구글, .. return이 가장 높은 곳에 투자)
			* 채널 안에서 다양한 형태의 캠페인
			* 마케팅 어트리뷰션 - 어떤 사람이 방문했을때 어디서 왔는지 알아야 함
			* 채널별로 어트리뷰션 정보와 내부 정보를 드리븐함
			* 매일 아침에 리포트가 만들어짐
	* 유데미
		* 사기탐지
			* 모델링
			* 정상거래와 사기 데이터를 많이 모아야 함
			* 머신러닝 Bias - 중국에서 사기가 많이 일어남. 모든 중국 사람들이 사기치는 것은 아님
			* 현상을 반영한다고 해도 현실의 문제를 왜곡할수도 있다.
			* 개인화로 머신러닝 모델 
	* 디지털 헬스케어 스타트업
		* 65이상 노인들에게 디바이스와 앱으로 체중, 혈당 혈압 체크로 질병을 예측
		* 보통 병원과 같이 일을 함
* Lesson and Learn 
	* 데이터 관련 비용이 생각보다 많이 일어난다.
		* 데이터를 통해서 매출을 올리지 못하면 질문이 많이 생긴다.
		* 직간접적으로 매출에 도움이 되는 것을 밝혀야한다. A/B 테스트가 꼭 필요하다.
		* 얼마나 매출이 증가했는지 검증해야 한다. 
		* 추천엔진 만들때 A/B 테스트를 만들고 결과를 공헌도를 이야기해야 하기 때문이다. 
		* 매니저와 이야기를 많이 해서 기대수준에 맞게 바꿔야한다.
	* 인프라스트럭처가 먼저 선행되어야 한다.
		* 데이터 퀄리티가 중요하다.
		* source of truth 중요한 데이터는 하나의 테이블만 볼 수 있도록. 대시보드도 똑같다.
		* 대시보드가 너무 많아지면 대시보드 이름 검색하는 것도 필요해진다.
		* 데이터 디스커버리 이슈
	* 지표 먼저 생각하자
		* 내가 일을 할때 성공과 실패가 되는 지표를 설정
		* 가설을 가지고 있으면 더 좋다.
		* 지표는 객관적이어야 함 (A/B 테스트)
		* 데이터 인프라도 지표가 있으면 좋다.(모니터링 이야기하시는 듯)
	* 간단할수록 더 좋은 솔루션이다.
		* 간단하게 시작해서 한바퀴 돌고 안되면 고도화하고
		* 모든 문제를 딥러닝으로 풀 이유가 없다.

### 2. 데이터 엔지니어링이란?
* 퀴즈1
	* 스킵스쿠터 전동스쿠터 회사 컨설팅
	* 1번째 하는 일 - 이 회사를 쓰는 사람들 중 중요한 사람들이 누구인가? (돈 많이 쓰는 사람들)
	* 그 사람들이 누구고 왜 매일 사용하는가? (active 사용자, 돈 많이 쓰는 사람이 누구인지?)
	* 돈 많이 쓰다가 2-3달 뒤면 없어짐. -> Churn Rate 이탈율 2-3달 이후 이탈율이 확 높아짐. 이유가 뭘까?
	* 개인 스쿠터를 구매
	* 서베이를 돌렸더니
* 퀴즈2 
	* 하머나이즈 헬스
	* 노인 환자들 중 매달 16프로가 트러블슈팅 콜을 함, 84프로는 안함 
	* 이탈율 비교해보자
		* 트러블슈팅 콜 안한 사람들이 이탈율이 높음
	* 데이터분석시 눈에 보이는 것 이외에 앞단에 무슨일이 있었는지 상상해보자.
* Different Roles
	* DW 관리
	* 데이터 파이프라인 생성 및 관리(Data pipeline == ETL == DAG)
	* 데이터 파이프라인의 타입
		* 배치 vs 실시간
		* A/B 테스트 분석 형태의 파이프라인 구축
		* 데이터 마트 생성
		* 서머리 데이터 생성 관리 (데이터 분석가가 관리함)(DBT - Analytics Enginner)
	* 이벤트 컬렉션
		* User's behavioral data
	* Skillset
		* **SQL**, **PYTHON**/Scala/Java, **Spark/YARN**
		* 머신러닝, A/B 테스팅, 통계 지식
		* 클라우드 컴퓨팅
		* ETL/ELT 스케줄러 : Airflow, .. 
* 성장하는 스타트업
	* 데이터가 없음. 인프라도 필요없음. 생존의 문제
	* 데이터가 생겨도 써드파티 ETL 서비스
		* Stitch .. 
	* 성장할때는 데이터 분석가 먼저 뽑음(대부분)
	* production database에 쿼리를 날림
	* production database
		* 속도가 중요함
		* 서비스 운영에 대한 정보만 들어감
	* dw - 데이터 분석을 위한 db
		* 운영 이외에 필요한 정보도 넣음
		* 크기가 중요함. 속도는 상대적으로 중요도 적음
	* 데이터 인프라, 데이터 웨어하우스를 만들고 ..
	* 상황에 맞게 다룸
	* ETL
		* 실행 순서 정의 
		* 처음엔 cronjob 쓰면 된다. 
		* 앞단의 굉장히 많은 프레임워크가 나왔지만 요즘엔 Airflow를 많이 사용함
	* 스텝2
		* 서머리 테이블을 주기적으로 만들고 지표를 시각화 함
		* 데이터 과학자가 들어와서 개인화 / 운영 최적화, 검색을 똑똑하게 만든다든지 함
		* 과학자가 들어오면 모델 만드는 일이 커지기 시작함
			* 데이터 패턴이 바뀜(데이터가 바뀌기 때문에) - 모델 성능을 주기적으로 만들어주어야 함
		* 피처 계산을 spark을 사용해서 큰 스케일로 사용해야 함
		* 데이터 과학자를 위한 인프라를 만들어주어야 함

